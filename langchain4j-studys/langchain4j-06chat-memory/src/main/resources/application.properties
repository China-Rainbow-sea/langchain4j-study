server.port=9006

spring.application.name=langchain4j-06chat-memory

# \u8BBE\u7F6E\u54CD\u5E94\u7684\u5B57\u7B26\u7F16\u7801\uFF0C\u907F\u514D\u6D41\u5F0F\u8FD4\u56DE\u8F93\u51FA\u4E71\u7801(Set the character encoding of the response to avoid garbled output in the stream return)
server.servlet.encoding.charset=utf-8
server.servlet.encoding.enabled=true
server.servlet.encoding.force=true

# https://docs.langchain4j.dev/tutorials/spring-boot-integration
#langchain4j.open-ai.chat-model.api-key=${aliQwen-api}
#langchain4j.open-ai.chat-model.model-name=qwen-plus
#langchain4j.open-ai.chat-model.base-url=https://dashscope.aliyuncs.com/compatible-mode/v1
# \u5927\u6A21\u578B\u8C03\u7528\u4E0D\u53EF\u4EE5\u660E\u6587\u914D\u7F6E\uFF0C\u4F60\u5982\u4F55\u89E3\u51B3\u8BE5\u95EE\u9898(Large model calls cannot be configured in plain text. How do you solve this problem)
# 1 yml\uFF1A                ${aliQwen-api}\uFF0C\u4ECE\u73AF\u5883\u53D8\u91CF\u8BFB\u53D6(Read from the environment variable)
# 2 config\u914D\u7F6E\u7C7B\uFF1A      System.getenv("aliQwen-api")\u4ECE\u73AF\u5883\u53D8\u91CF\u8BFB\u53D6

